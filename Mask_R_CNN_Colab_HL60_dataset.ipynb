{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mask-R-CNN_Colab_HL60_dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNDmUCHBSDEINawTybzzDn1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryujiuno0323/Mask_R_CNN/blob/master/Mask_R_CNN_Colab_HL60_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbHkHwDRMpfy",
        "colab_type": "text"
      },
      "source": [
        "#Mask-R-CNN_Colab_HL60_dataset\n",
        "\n",
        "データセット　HL60 CELL LINE (FIXED CELLS)\n",
        "https://horomary.hatenablog.com/entry/2019/07/28/124000\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hd8Puiy-MY9n",
        "colab_type": "text"
      },
      "source": [
        "1.Google Colaboratory上で新しい実行空間を作成し、GPUを有効にする\n",
        "\n",
        "2.GitHubからMask R-CNNのソースコードを取得し、セットアップする\n",
        "GitHubからCOCO APIのソースコードを取得し、セットアップする\n",
        "\n",
        "3.COCOデータセットで訓練済のMask R-CNN学習済モデルをダウンロードする\n",
        "\n",
        "4.それを使ってサンプル画像を推論させて、結果を画面に表示する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D4t85pr4SxS0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9fff493e-7f26-46e6-bdc6-12e8e2ad268f"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vpeSdk2PSxS5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1dea6668-efa1-47a9-b102-7a8334bba801"
      },
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tw-FhlC8zpdn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "3be6e034-9b92-4566-8962-b06a25f4cb19"
      },
      "source": [
        "!pip3 install keras==2.2.5"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.1.2)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBpFNQbPC1kr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjqTIVYkwRZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "print(keras.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6A1WcSHEdGe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "936e1e82-fd03-46cd-e715-dc5c55b99af6"
      },
      "source": [
        "import os\n",
        "\n",
        "p_temp=os.getcwd()\n",
        "print(p_temp)\n",
        "#取得したディレクトリの配下のディレクトリ確認\n",
        "print(os.listdir(path=p_temp))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/coco/PythonAPI\n",
            "['pycocotools', 'setup.py', 'pycocoDemo.ipynb', 'pycocotools.egg-info', 'mask_rcnn_coco.h5', 'build', 'logs', 'dist', 'pycocoEvalDemo.ipynb', 'Makefile']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Obi3-ulWEXJt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gitからソースを取得\n",
        "# 依存パッケージのインストール\n",
        "#matterport/MASK_RCNNリポジトリを\n",
        "#clone(https://github.com/matterport/Mask_RCNN)\n",
        "%cd /content\n",
        "!git clone https://github.com/matterport/Mask_RCNN.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d783IqLwEeZc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "p_temp=os.getcwd()\n",
        "print(p_temp)\n",
        "#取得したディレクトリの配下のディレクトリ確認\n",
        "print(os.listdir(path=p_temp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqCuqDRPN8e3",
        "colab_type": "text"
      },
      "source": [
        "#1.Mask R-CNNのソースコードを取得し、セットアップする\n",
        "\n",
        "GitHubからMask R-CNNのソースコードを取得します。Colaboratoryが提供してくれる仮想マシン上の \"/content\" ディレクトリにソースがクローンされるようにします。次に、Mask R-CNNが必要とするnumpy, tensorflow, kerasなどのライブラリはリポジトリに含まれる \"requirements.txt\" に記載されていますので、こちらを全てpipでインストールします。最後に、リポジトリに含まれるセットアップスクリプト \"setup.py\" を実行して完了です。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PncINkMSNib0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "9b18fc5f-38b6-480a-c6ff-093204e979c5"
      },
      "source": [
        "# gitからソースを取得\n",
        "# 依存パッケージのインストール\n",
        "#matterport/MASK_RCNNリポジトリを\n",
        "#clone(https://github.com/matterport/Mask_RCNN)\n",
        "%cd /content\n",
        "!git clone https://github.com/matterport/Mask_RCNN.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'Mask_RCNN'...\n",
            "remote: Enumerating objects: 956, done.\u001b[K\n",
            "remote: Total 956 (delta 0), reused 0 (delta 0), pack-reused 956\u001b[K\n",
            "Receiving objects: 100% (956/956), 116.76 MiB | 27.82 MiB/s, done.\n",
            "Resolving deltas: 100% (566/566), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4Sod7L_MoPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ライブラリを取得\n",
        "%cd /content/Mask_RCNN\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNFl3zEdOGMH",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmNWlCXtNuiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setup.pyを実行\n",
        "#matterport/MASK_RCNNのインストール\n",
        "#MASK_RCNNの最上位ディレクトリでpython setup.py install\n",
        "%cd /content/Mask_RCNN\n",
        "%run -i setup.py install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CNQvrnoOBd7",
        "colab_type": "text"
      },
      "source": [
        "#2.COCO APIのソースコードを取得し、セットアップする\n",
        "\n",
        "GitHubからCOCO APIのソースコードを取得します。リポジトリに含まれるセットアップスクリプト \"setup.py\" を実行して完了です。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwKr8jVNORjM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "158610fd-fd85-4ea7-e20c-78eada6a0bda"
      },
      "source": [
        "# COCO 用ソースを取得\n",
        "# pycocotoolsのインストール\n",
        "# cocoリポジトリをclone(https://github.com/waleedka/coco)\n",
        "%cd /content\n",
        "!git clone https://github.com/waleedka/coco.git"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'coco'...\n",
            "remote: Enumerating objects: 904, done.\u001b[K\n",
            "remote: Total 904 (delta 0), reused 0 (delta 0), pack-reused 904\u001b[K\n",
            "Receiving objects: 100% (904/904), 10.39 MiB | 11.55 MiB/s, done.\n",
            "Resolving deltas: 100% (539/539), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNh3OAseOYPr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# python用APIをインストール\n",
        "# matterport/MASK_RCNNのインストール\n",
        "# MASK_RCNNの最上位ディレクトリでpython setup.py install\n",
        "\n",
        "%cd /content/coco/PythonAPI\n",
        "%run -i setup.py build_ext --inplace\n",
        "%run -i setup.py build_ext install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EQjIm4fc7Dn",
        "colab_type": "text"
      },
      "source": [
        "Configクラスについて\n",
        "\n",
        "OneClassConfigではmrcnn.configからConfigクラスを継承して訓練の設定を行います。\n",
        "※バッチ当たりの画像数は増やしすぎるとGPUメモリに乗りません。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eqbvHULc3U9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from mrcnn.config import Config\n",
        "\n",
        "\n",
        "class OneClassConfig(Config):\n",
        "\n",
        "    #: config名\n",
        "    NAME = \"cell_dataset\"\n",
        "\n",
        "    #: バッチあたり画像数 (GPUのメモリが大きいなら増やしてもよい\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "    # クラス数　= 背景 + 検出クラス数\n",
        "    NUM_CLASSES = 1 + 1\n",
        "\n",
        "    # エポックあたりステップ数\n",
        "    STEPS_PER_EPOCH = 50\n",
        "\n",
        "    VALIDATION_STEPS = 5\n",
        "\n",
        "    # 提案領域のconfidenceが90%以下なら物体検出フェイズをスキップ\n",
        "    DETECTION_MIN_CONFIDENCE = 0.9"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvxvCxCcdCew",
        "colab_type": "text"
      },
      "source": [
        "Datasetクラスについて\n",
        "\n",
        "OneClassDatasetではmrcnn.utilsからDatasetクラスを継承して画像読み込みメソッドの定義ととmask生成のメソッドのオーバーライドを行います。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5olDzb2dWhs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c6ef9c59-d4a9-4be3-9a85-c6dad68162db"
      },
      "source": [
        "import pathlib\n",
        "\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from mrcnn import utils\n",
        "from mrcnn.model import log\n",
        "\n",
        "\n",
        "class OneClassDataset(utils.Dataset):\n",
        "\n",
        "    def load_dataset(self, dataset_dir):\n",
        "        \"\"\" データセットを登録\n",
        "        \"\"\"\n",
        "        #: データセット名、クラスID、クラス名\n",
        "        self.add_class('cell_dataset', 1, 'cell')\n",
        "\n",
        "        images = glob.glob(os.path.join(dataset_dir, \"image\", \"*.jpg\"))\n",
        "        masks = glob.glob(os.path.join(dataset_dir, \"mask\", \"*.jpg\"))\n",
        "\n",
        "        for image_path, mask_path in zip(images, masks):\n",
        "            image_path = pathlib.Path(image_path)\n",
        "            mask_path = pathlib.Path(mask_path)\n",
        "            assert image_path.name == mask_path.name, 'データセット名不一致'\n",
        "\n",
        "            image = Image.open(image_path)\n",
        "            height = image.size[0]\n",
        "            width = image.size[1]\n",
        "\n",
        "            mask = Image.open(mask_path)\n",
        "            assert image.size == mask.size, \"サイズ不一致\"\n",
        "\n",
        "            self.add_image(\n",
        "                'cell_dataset',\n",
        "                path=image_path,\n",
        "                image_id=image_path.stem,\n",
        "                mask_path=mask_path,\n",
        "                width=width, height=height)\n",
        "\n",
        "    def load_mask(self, image_id):\n",
        "        \"\"\"マスクデータとクラスidを生成する\n",
        "        \"\"\"\n",
        "        image_info = self.image_info[image_id]\n",
        "        if image_info[\"source\"] != 'cell_dataset':\n",
        "            return super(self.__class__, self).load_mask(image_id)\n",
        "\n",
        "        mask_path = image_info['mask_path']\n",
        "        mask, cls_idxs = blob_detection(str(mask_path))\n",
        "\n",
        "        return mask, cls_idxs\n",
        "\n",
        "    def image_reference(self, image_id):\n",
        "        \"\"\"Return the path of the image.\"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        if info[\"source\"] == 'cell_dataset':\n",
        "            return info\n",
        "        else:\n",
        "            super(self.__class__, self).image_reference(image_id)\n",
        "\n",
        "\n",
        "def blob_detection(mask_path):\n",
        "    mask = cv2.imread(mask_path, 0)\n",
        "   #: 念のためもう一度二値化\n",
        "    _, mask = cv2.threshold(mask, 150, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    label = cv2.connectedComponentsWithStats(mask)\n",
        "    data = copy.deepcopy(label[1])\n",
        "\n",
        "    labels = []\n",
        "    for label in np.unique(data):\n",
        "        #: ラベル0は背景\n",
        "        if label == 0:\n",
        "            continue\n",
        "        else:\n",
        "            labels.append(label)\n",
        "\n",
        "    mask = np.zeros((mask.shape)+(len(labels),), dtype=np.uint8)\n",
        "\n",
        "    for n, label in enumerate(labels):\n",
        "        mask[:, :, n] = np.uint8(data == label)\n",
        "\n",
        "    cls_idxs = np.ones([mask.shape[-1]], dtype=np.int32)\n",
        "\n",
        "    return mask, cls_idxs"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blY8oQ5s3fS9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "0239122b-a8a0-41a5-cea0-c1e329c3e9d8"
      },
      "source": [
        "import os\n",
        "\n",
        "p_temp=os.getcwd()\n",
        "print(p_temp)\n",
        "#取得したディレクトリの配下のディレクトリ確認\n",
        "print(os.listdir(path=p_temp))\n",
        "#絶対パス\n",
        "#file = os.path.abspath(\"sample_data\")\n",
        "#file = os.path.abspath(\"model.py\")\n",
        "file = os.path.abspath(\"mrcnn/model.py\")\n",
        "\n",
        "\n",
        "print(file)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/coco/PythonAPI\n",
            "['pycocotools', 'setup.py', 'pycocoDemo.ipynb', 'pycocotools.egg-info', 'build', 'dist', 'pycocoEvalDemo.ipynb', 'Makefile']\n",
            "/content/coco/PythonAPI/mrcnn/model.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eifPT7ORdxjM",
        "colab_type": "text"
      },
      "source": [
        "学習実行\n",
        "\n",
        "モデル訓練のコードです。cocoデータセット学習済み重みをモデルへロードした後、DatasetクラスとConfigクラスをモデルへ渡して訓練開始。\n",
        "※DatasetクラスとConfigクラスの詳細は後述"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQVhLYYYeNq0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "69a75523-ac0c-4a70-cc39-12e72165f954"
      },
      "source": [
        "    import os\n",
        "    import glob\n",
        "\n",
        "    import mrcnn.model as modellib\n",
        "    from mrcnn import utils\n",
        "\n",
        "\n",
        "    TRAIN_DATASET = os.path.join('dataset', 'train')\n",
        "    dataset_train = OneClassDataset()\n",
        "    dataset_train.load_dataset(TRAIN_DATASET)\n",
        "    dataset_train.prepare()\n",
        "\n",
        "    VALID_DATASET = os.path.join('datset', 'valid')\n",
        "    dataset_val = OneClassDataset()\n",
        "    dataset_val.load_dataset(VALID_DATASET)\n",
        "    dataset_val.prepare()\n",
        "\n",
        "    config = OneClassConfig()\n",
        "\n",
        "\n",
        "    model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
        "                              model_dir=\"logs/model\")\n",
        "\n",
        "    COCO_MODEL_PATH = 'mask_rcnn_coco.h5'\n",
        "    if not os.path.exists(COCO_MODEL_PATH):\n",
        "        utils.download_trained_weights(COCO_MODEL_PATH)\n",
        "    \n",
        "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
        "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
        "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "\n",
        "   #: ネットワークのhead部分のみの訓練\n",
        "    model.train(dataset_train, dataset_val,\n",
        "                learning_rate=0.001,\n",
        "                epochs=10,\n",
        "                layers='heads')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting at epoch 0. LR=0.001\n",
            "\n",
            "Checkpoint Path: logs/model/cell_dataset20200619T1008/mask_rcnn_cell_dataset_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "In model:  rpn_model\n",
            "    rpn_conv_shared        (Conv2D)\n",
            "    rpn_class_raw          (Conv2D)\n",
            "    rpn_bbox_pred          (Conv2D)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py:49: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1692, in data_generator\n    image_index = (image_index + 1) % len(image_ids)\nZeroDivisionError: integer division or modulo by zero\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\", line 641, in next_sample\n    return six.next(_SHARED_SEQUENCES[uid])\n  File \"/usr/local/lib/python3.6/dist-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\", line 1810, in data_generator\n    dataset.image_info[image_id]))\nUnboundLocalError: local variable 'image_id' referenced before assignment\n\"\"\"",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/content/coco/PythonAPI/setup.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             layers='heads')\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, val_dataset, learning_rate, epochs, layers, augmentation, custom_callbacks, no_augmentation_sources)\u001b[0m\n\u001b[1;32m   2372\u001b[0m             \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2373\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2374\u001b[0;31m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2375\u001b[0m         )\n\u001b[1;32m   2376\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    731\u001b[0m                     \u001b[0;34m\"`use_multiprocessing=False, workers > 1`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m                     \"For more information see issue #1638.\")\n\u001b[0;32m--> 733\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m                     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mnext_sample\u001b[0;34m()\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mnext\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0muid\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m     \"\"\"\n\u001b[0;32m--> 641\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_SHARED_SEQUENCES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\u001b[0m in \u001b[0;36mdata_generator\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1808\u001b[0m             \u001b[0;31m# Log it and skip the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m             logging.exception(\"Error processing image {}\".format(\n\u001b[0;32m-> 1810\u001b[0;31m                 dataset.image_info[image_id]))\n\u001b[0m\u001b[1;32m   1811\u001b[0m             \u001b[0merror_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merror_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'image_id' referenced before assignment"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awudoQE2DK_E",
        "colab_type": "text"
      },
      "source": [
        "結果の確認\n",
        "\n",
        "validation データセットについて結果の確認を行います。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-6p6QV61tNw",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nI-KcSXDE7G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "outputId": "9cb568ff-408a-468b-df87-bbd583ce5fac"
      },
      "source": [
        "    import random\n",
        "    from mrcnn import visualize\n",
        "\n",
        "    VALID_DATASET = os.path.join('dataset', 'valid')\n",
        "    dataset_val = OneClassDataset()\n",
        "    dataset_val.load_dataset(VALID_DATASET)\n",
        "    dataset_val.prepare()\n",
        "\n",
        "    config = InferenceConfig()\n",
        "    MODEL_DIR = os.path.join(\"logs\", \"model\")\n",
        "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR,\n",
        "                              config=config)\n",
        "    \n",
        "    weights_path = model.find_last()\n",
        "    print(\"Loading weights \", weights_path)\n",
        "    model.load_weights(weights_path, by_name=True)\n",
        "\n",
        "    \n",
        "    random.choice(dataset_val.image_ids)\n",
        "    image, image_meta, gt_class_id, gt_bbox, gt_mask = modellib.load_image_gt(dataset_val, config, image_id)\n",
        "    info = dataset_val.image_info[image_id]\n",
        "    \n",
        "    results = model.detect([image], verbose=1)\n",
        "\n",
        "    # Display results\n",
        "    ax = get_ax(1)\n",
        "    r = results[0]\n",
        "    visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'],\n",
        "                                dataset_val.class_names, r['scores'], ax=ax,\n",
        "                                title=\"Predictions\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/content/coco/PythonAPI/setup.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdataset_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInferenceConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mMODEL_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"logs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR,\n",
            "\u001b[0;31mNameError\u001b[0m: name 'InferenceConfig' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koTmyTxVOl-b",
        "colab_type": "text"
      },
      "source": [
        "#3.COCOデータセットで訓練済のMask R-CNN学習済モデルをダウンロードする\n",
        "\n",
        "ここからはPythonを使ったコーディングになります。同様のソースコードが、Mask R-CNNリポジトリの \"samples/demo.ipynb\" にあるため、そちらをコピペして実行しても同じ結果が得られます。その場合、冒頭のROOT_DIR変数を仮想マシン上のパスである \"/content/Mask_RCNN\" に書き換える必要があるため、注意しましょう。\n",
        "\n",
        "以下は、各種初期設定と、COCOデータセットで訓練済のMask R-CNN学習済モデルをダウンロードするまでの一連の処理となります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9TTfxY9OdXe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "114404c5-3262-477c-c4c6-599bb04949d7"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import skimage.io\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath(\"/content/Mask_RCNN\")\n",
        "\n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "from mrcnn import utils\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn import visualize\n",
        "# Import COCO config\n",
        "sys.path.append(os.path.join(ROOT_DIR, \"samples/coco/\"))  # To find local version\n",
        "import coco\n",
        "\n",
        "%matplotlib inline \n",
        "\n",
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "# Local path to trained weights file\n",
        "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "# Download COCO trained weights from Releases if needed\n",
        "if not os.path.exists(COCO_MODEL_PATH):\n",
        "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
        "\n",
        "# Directory of images to run detection on\n",
        "IMAGE_DIR = os.path.join(ROOT_DIR, \"images\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/usr/local/lib/python3.6/dist-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/model.py\"\u001b[0;36m, line \u001b[0;32m2199\u001b[0m\n\u001b[0;31m    self.keras_model.metrics_tensors.append（loss、name）\u001b[0m\n\u001b[0m                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjqv56pQPBBy",
        "colab_type": "text"
      },
      "source": [
        "#4.サンプル画像を推論して、結果を画面に表示する\n",
        "\n",
        "これで全ての準備が整ったため、Mask R-CNNリポジトリに含まれるサンプル画像を読み込ませて推論させていきます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wn1aaKA7O_jj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InferenceConfig(coco.CocoConfig):\n",
        "    # Set batch size to 1 since we'll be running inference on\n",
        "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "config = InferenceConfig()\n",
        "# config.display()\n",
        "\n",
        "\n",
        "# Create model object in inference mode.\n",
        "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
        "\n",
        "# Load weights trained on MS-COCO\n",
        "model.load_weights(COCO_MODEL_PATH, by_name=True)\n",
        "\n",
        "\n",
        "# COCO Class names\n",
        "# Index of the class in the list is its ID. For example, to get ID of\n",
        "# the teddy bear class, use: class_names.index('teddy bear')\n",
        "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
        "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
        "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
        "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
        "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
        "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
        "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
        "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
        "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
        "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
        "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
        "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
        "               'teddy bear', 'hair drier', 'toothbrush']\n",
        "\n",
        "\n",
        "# Load a random image from the images folder\n",
        "file_names = next(os.walk(IMAGE_DIR))[2]\n",
        "for file_name in file_names:\n",
        "  image = skimage.io.imread(os.path.join(IMAGE_DIR, file_name))\n",
        "\n",
        "  # Run detection\n",
        "  results = model.detect([image], verbose=1)\n",
        "\n",
        "  # Visualize results\n",
        "  r = results[0]\n",
        "  visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
        "                              class_names, r['scores'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}